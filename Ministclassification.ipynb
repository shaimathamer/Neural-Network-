{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ministclassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5ENv7HhkjTKyiN0lOdLRI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaimathamer/Neural-Network-/blob/main/Ministclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZelfrNdskQEg"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as se"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHhxuZHvrr9Y"
      },
      "source": [
        "def activation (x):\r\n",
        "  act=1/(1+np.exp(-x))\r\n",
        "  return act\r\n",
        "\r\n",
        "def deactivation(y):\r\n",
        "  de_act=y*(1-y)\r\n",
        "  return de_act"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfdEINbrruBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461f6bb1-6e4d-4f58-90c8-77521599ef2a"
      },
      "source": [
        "data=pd.read_csv('/content/sample_data/mnist_train_small.csv',header=None)\r\n",
        "batch_size=2000\r\n",
        "batches= []\r\n",
        "N=len(data)\r\n",
        "for batch_n,batch in data.groupby(np.arange(N)//batch_size):\r\n",
        "  #print(batch_n,batch)\r\n",
        "  x=batch.iloc[:,1:785]\r\n",
        "  x=x/255\r\n",
        "  N=len(x)\r\n",
        "  one=np.ones((1,N))\r\n",
        "  xp=np.concatenate((one.T,x),axis=1)\r\n",
        "  Y=batch.iloc[:,0]\r\n",
        "  y=pd.get_dummies(Y)#convert label  to 0 or 1\r\n",
        "  y=y.values\r\n",
        "  batches.append((xp,y))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#print(Y)\r\n",
        "#img=x.iloc[4].values\r\n",
        "#plt.imshow(img.reshape(28,28),cmap=plt.cm.gray)\r\n",
        "#plt.show()\r\n",
        "\r\n",
        "np.random.seed(0)\r\n",
        "input_nod=784\r\n",
        "hidden_nod=100\r\n",
        "out_nod=10\r\n",
        "widthi=2*np.random.rand(hidden_nod,input_nod+1)-1\r\n",
        "widtho=2*np.random.rand(out_nod,hidden_nod+1)-1\r\n",
        "\r\n",
        "#XP=ny.c_[one,x]\r\n",
        "\r\n",
        "epochs=500\r\n",
        "learning_rate= 1\r\n",
        "for epoch in range(epochs):\r\n",
        "  for xp,y in batches:\r\n",
        "      N=len(x)\r\n",
        "      one=np.ones((1,N))\r\n",
        "\r\n",
        "  #fowrowd\r\n",
        "      x_input=widthi @ xp.T\r\n",
        "      y_hiden=activation(x_input)\r\n",
        "      y_hiden=np.concatenate((one,y_hiden))  \r\n",
        "      ywho=widtho @ y_hiden\r\n",
        "      y_predicatied=activation(ywho)\r\n",
        "  #backward\r\n",
        "      errror=y.T-y_predicatied\r\n",
        "  #print('Y_Acual',y,'Y-Predicted',y_predicatied,)\r\n",
        "      los=0.5*np.mean(errror**2)\r\n",
        "  #print(los)\r\n",
        "  #######################from here will start work back probgation to genertae gradiant \r\n",
        "  \r\n",
        "      error_hid=(errror*deactivation(y_predicatied)).T @ widtho[:,1:]\r\n",
        "      gradient_h=-(1/N)*(errror*deactivation(y_predicatied))@ y_hiden.T\r\n",
        "      gradiant_in=-(1/N)*(error_hid.T * deactivation(y_hiden[1:,:]))@ xp\r\n",
        "      widtho=widtho -(learning_rate*gradient_h)\r\n",
        "      widthi=widthi -(learning_rate*gradiant_in)\r\n",
        " # print(gradient_h)\r\n",
        "\r\n",
        "  if epoch%(epochs/10) == 0:\r\n",
        "       los=0.5*np.mean(errror**2)\r\n",
        "    \r\n",
        "#############to see how the model perform for all intir data\r\n",
        "x=data.iloc[:,1:785]\r\n",
        "x=x/255\r\n",
        "N=len(x)\r\n",
        "one=np.ones((1,N))\r\n",
        "xp=np.concatenate((one.T,x),axis=1)\r\n",
        "Y=data.iloc[:,0]\r\n",
        "y=pd.get_dummies(Y)#convert label  to 0 or 1\r\n",
        "y=y.values\r\n",
        "x_input=widthi @ xp.T\r\n",
        "y_hiden=activation(x_input)\r\n",
        "y_hiden=np.concatenate((one,y_hiden))  \r\n",
        "ywho=widtho @ y_hiden\r\n",
        "y_predicatied=activation(ywho)\r\n",
        "data['prdictedit']=y_predicatied[0]\r\n",
        "#print(data)\r\n",
        "label_predict=np.argmax(y_predicatied,axis=0)\r\n",
        "print(np.sum(label_predict==Y)/N)\r\n",
        "\r\n",
        "\r\n",
        " # ee=0.5*ny.mean((y-y_predicatied,)\r\n",
        "  #print(ee)\r\n",
        " "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9379\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}